---
title: Instagram â€“ %%date%%
author: Digital Rights Watch
date: 2020-10-02T02:00:38+00:00
draft: true
url: /?p=7317
featureImage: /wp-content/uploads/2020/10/120363937_2045108915624925_5677084963049232218_n.jpg
instagrate_id:
  - 17909326825510122
categories:
  - Articles
format: image

---
Predictive policing is \*incredibly\* problematic. It relies on historical data that is riddled with racial bias and perpetuates harmful racial profiling. It also hasn't been shown to reduce crime. "Smart" policing is something that often comes up when people and governments talk about smart cities. But really, is implementing a tool that is known to cause harm really all that smart?We don't think so. Head to drw.fyi/cities to join us in asking local councils to uphold human rights in their smart city plans. [Image Description: a screenshot of a tweet from the DRW Twitter on a blue and yellow background. The tweet reads: "Predictive policing raises lots of human rights issues including racial bias and discrimination, and so far has not been shown to be effective at reducing crime. This is the kind of think we do NOT want to see in a smart city." with a link to an article from UNSW called: "Predictive policing: will you do time before the crime?"]  
<img decoding="async" src="/wp-content/uploads/2020/10/120363937_2045108915624925_5677084963049232218_n.jpg" alt="Instagram - %%date%%" />