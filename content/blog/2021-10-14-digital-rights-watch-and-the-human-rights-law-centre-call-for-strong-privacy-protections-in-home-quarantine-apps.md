---
title: Rights groups call for strong privacy protections in home quarantine apps
author: Samantha
authorThumb: /wp-content/uploads/2019/08/SamFloreani-150x150.png
date: 2021-10-13T20:20:05+00:00
url: /2021/10/14/digital-rights-watch-and-the-human-rights-law-centre-call-for-strong-privacy-protections-in-home-quarantine-apps/
featureImage: /wp-content/uploads/2021/10/dogherine-1p7WkGACGw-unsplash-1.jpg
cybocfi_hide_featureImage:
  - yes
eg_vimeo_ratio:
  - 1
eg_youtube_ratio:
  - 1
eg_wistia_ratio:
  - 1
eg_html5_ratio:
  - 1
eg_soundcloud_ratio:
  - 1
eg_custom_meta_216:
  - 'true'
categories:
  - Media releases
  - News
tags:
  - covid-19
  - Facial recognition
  - privacy

---


The Human Rights Law Centre and Digital Rights Watch have written to federal, state and territory health ministers calling for stronger privacy protections in the technology being used to support home quarantine trials.

The call comes after the South Australian government last month announced the trial of a new home quarantine smartphone app. The app would support compliance and enforcement of health rules by using geolocation and facial recognition software to confirm an individuals' identity and location at various intervals while under home quarantine. Other states across Australia are now following suit, with New South Wales, Victoria and Tasmania announcing similar trials.

The joint letter acknowledges the important role of technology in helping manage the impact of COVID-19 on Australians and in facilitating the necessary transition from hotel to home quarantine arrangements. However, the letter urges the ministers to adopt strong safeguards against the misuse of personal information.

**Samantha Floreani, Program Lead, Digital Rights Watch said:**

"Significant effort went into ensuring that the legislation governing the COVIDSafe app had a strong focus on privacy. This should be the baseline for any technological approach to managing the public health response to COVID-19.

"The information collected by the home quarantine app, as well as that collected via QR 'check ins', is no less sensitive to that which was to be collected by the COVIDSafe app. Individuals should be able to trust that the personal information they are providing will only be used to support the public health response to COVID-19, and nothing else."

The letter warns that there have already been several well-documented cases of law enforcement authorities seeking to access QR 'check in' data, which undermines community trust and erodes the efficacy of contact tracing efforts. Without robust protections in place, the information collected by home quarantine apps could later be used for secondary purposes in similar ways.

"As we move into the next phase of the pandemic, Australians will not be in a position to make meaningful choices about whether or not they provide personal information in home quarantine. Therefore Australian governments must ensure the data they collect during home quarantine is retained for no longer than necessary and is not misused or disclosed for non-health-related purposes," Floreani said.

**Kieran Pender, Senior Lawyer, Human Rights Law Centre said:**

"We know from experience all around the world that facial recognition technology carries significant human rights and privacy risks. Its deployment in home quarantine must be subject to proper safeguards and transparency. There must be a clear ban on any of the data collected being used for any other purpose beyond public health compliance."

Leading authorities including the Australian Human Rights Commission and the UN High Commissioner for Human Rights have recently called for a moratorium on the use of facial recognition technology until there are appropriate regulatory frameworks in place. The joint letter calls on the ministers to commit to enacting such regulation.

"As an interim measure, home quarantine apps should perform identity and location-checking 'in-app', rather than transferring sensitive biometric data to an external, centralised database – as is currently occurring in home quarantine trials. That would be a more secure approach that would still permit the necessary verification to take place," Pender said.

In the letter, Digital Rights Watch and the Human Rights Law Centre also express concern about the potential adverse impact of facial recognition in home quarantine on users with darker skin tones.

"There is extensive evidence that facial recognition algorithms exhibit racial and gender biases, including by having a higher error rate when recognising individuals with darker skin tones. It would be alarming if users were subject negative consequences – such as police visits to monitor compliance – as a result of discriminatory technology," Pender said.



**CONTACT:**

Evan Schuurman, Media and Communications Manager, Human Rights Law Centre, 0406 117 937, evan.schuurman@hrlc.org.au

Samantha Floreani, Program Lead, Digital Rights Watch <samantha@digitalrightswatch.org.au>



### **<span style="text-decoration: underline;"><a href="/wp-content/uploads/2021/10/DRWHRLC-Letter-to-Ministers.pdf">Read the letter here</a>. </span>**
