---
title: 'Explainer: Basic Online Safety Expectations'
author: Samantha
authorThumb: /wp-content/uploads/2019/08/SamFloreani-150x150.png
date: 2021-11-01T02:49:01+00:00
url: /2021/11/01/bose/
featureImage: /wp-content/uploads/2021/10/bASIC-2.png
eg_soundcloud_ratio:
  - 1
eg_custom_meta_216:
  - 'true'
eg_vimeo_ratio:
  - 1
eg_youtube_ratio:
  - 1
eg_wistia_ratio:
  - 1
eg_html5_ratio:
  - 1
categories:
  - Articles
  - 'Tools &amp; Guides'
tags:
  - BOSE

---
The _Online Safety Act 2021_ passed in June this year and comes into effect on 23 January 2022. Under Part 4 of the legislation, the Minister has the power to determine something called the **Basic Online Safety Expectations** (BOSE).

*****Curious how this fits within the broader Online Safety Act? You can [<span style="text-decoration: underline;">read our initial explainer here</span>][1].

The draft BOSE declaration is currently under public consultation, and submissions are due on **12 November 2021.** Here is an overview of the key issues we’ve identified and how we propose addressing them. Please use this page and our submission as your own cheat sheet if you are writing one! You can also forward it to your MP.

##### **What’s included in the BOSE?**

In essence, it outlines the government’s expectations for social media services, relevant electronic services, and designated internet services.

Taken together, this means that the expectations will apply to basically any service and type of content on the internet. This of course includes social media, but it will also extend to include private messages and email. Really, any electronic communication services are covered by this.

The expectations require services to:

  * Ensure that end-users are able to use the service in a safe manner (core expectation 6.1)
  * Minimise provision of any of the following: cyber bullying or abuse material targeted at an Australian child or adult respectively, non-consensual sharing of intimate images, Class 1 Material, and material that promotes, incites, instructs or depicts abhorrent violent conduct (core expectation 11)
  * Prevent children from accessing Class 2 Material (core expectation 12.1)
  * Proactively minimise material that may be unlawful or harmful (additional expectation 6.2)
  * Prevent anonymous accounts being used to deal with material that is or may be unlawful or harmful (additional expectation 9.1)
  * Develop and implement processes to detect and address material that is or may be unlawful or harmful if the service uses encryption (additional expectation 8)

There are also expectations about ensuring there are mechanisms to report and make complaints about breaches of a service’s terms of use, to ensure there are policies in place, and to cooperate with providers of other services. We haven’t evaluated these as harmful to digital freedoms so we have not included them here.

**<span style="text-decoration: underline;"><a href="https://digitalrightswatch.org.au/2021/11/04/submission-draft-basic-online-safety-expectations/" target="_blank" rel="noreferrer noopener">You can read our full joint submission with Global Partners Digital on the BOSE here.</a></span>**

##### **What are our key concerns?**

There are aspects of the draft BOSE that, if passed in their current form, are likely to pose risks to individuals’ privacy, security, and freedom of expression, and violate Australia&#8217;s international human rights obligations.

Based on previous experience and research we fear that BOSE will:

  1. incentivise proactive, automated, and blanket removal of content,
  2. push services to prevent people interacting anonymously, and
  3. force services to undermine encryption.

**_Proactive, automated monitoring and removal of content_**

<p class="has-text-align-left">
  <em>Additional expectation &#8211; &#8220;The provider of the service will take reasonable steps to proactively minimise the extent to which material or activity on the service is or may be unlawful or harmful.</em>&#8220;
</p>

Given the scale and scope of content that is generated and shared online, platforms generally turn to automated processes, including AI, in order to perform some level of content moderation. We anticipate that this expectation will incentivise platforms to increase their use of such tools, to proactively monitor and remove content.

Unfortunately, automated content moderation has been shown time and time again to [be ineffective][2], and to disproportionately impact some groups over others, penalising [Black][3], [Indigenous][4], [fat][5], and [LGBTQ+][6] people. Automated processes have also not been effective at dealing with hate speech, which means it’s more likely to be a visual-based scheme, and less effective at identifying particular forms of abuse and bullying contained in text. Zuckerberg said in 2018, it’s ‘[easier to detect a nipple than hate speech with AI][7]’ and anyone who has spent much time online is likely to have seen this in practice.

We are concerned that this expectation is likely to result in discriminatory implementation and an overarching increase in blanket removal of content which may not be unlawful or harmful, but be swept up in an effort by services to meet this expectation.

**_Threatening anonymity_**

_Additional expectation &#8211; &#8220;If the service permits the use of anonymous accounts, the provider of the service will take reasonable steps to prevent those accounts being used to deal with material, or for activity, that is or may be unlawful or harmful._&#8220;

This expectation is supplemented with two examples of ‘reasonable steps’ which include: (a) preventing people from repeatedly using anonymous accounts or (b) having processes that require verification of identity.

This expectation, in combination with the reasonable steps, will threaten the ability of people to be anonymous online. We won&#8217;t go into more detail here, but anonymity online is extremely important for a range of reasons → [we wrote about it here][8].

**_Undermining encryption_**

_Additional Expectation &#8211; &#8220;If the service uses encryption, the provider of the service will take reasonable steps to develop and implement processes to detect and address material or activity on the service that is or may be unlawful or harmful_.&#8221;

We are extremely concerned with the inclusion of this expectation, as it stands to push services to undermine encryption, which is essential for our individual and collective digital security. This expectation frames encryption as an inhibitor to safety, which runs counter to the general consensus in the cybersecurity industry that encryption is vital to facilitate safety.

Encryption supports the security of our online activities; protecting data from potential cybercriminals, enabling secure online transactions, and maintaining the privacy and security of our online communications, including those of children. For example, encryption plays a crucial role in preventing malicious actors from accessing networked devices, including tapping into users’ webcams or baby monitors. This additional obligation would potentially undermine the security of Australians&#8217; encrypted services, jeopardizing the safety of the millions of people who rely on them each day.

Want to know more about why encryption is so important? [Check out this expert session][9] we hosted for Encryption Day.

#### **Want to write your own submission? Here are some tips!**

  * If you’re feeling overwhelmed or not sure where to start, or would like a hype team to get you inspired to write a submission, [check out this online workshop][10] we hosted with Electronic Frontiers Australia on how to write your own policy submission. 
  * Remember that your submission doesn’t need to be long or complicated. It’s okay to make a short and to the point submission—in fact, it’s great! One page!
  * Note that the Online Safety Act prescribes the core expectations which are included in the BOSE Determination, and they cannot be amended. But you can still suggest that additional expectations are included to add context or safeguards around the core expectations. 
  * Feel free to take inspiration from <a href="https://digitalrightswatch.org.au/2021/11/04/submission-draft-basic-online-safety-expectations/" target="_blank" rel="noreferrer noopener">our submission</a> (that’s why we’re sharing it!) but remember that your submission will be more powerful if you don’t copy-paste. Take the ideas, and make them your own! Including your own personal experience or personal concerns will have the most impact.
  * You can reference our submission in your own to add additional support. For example, you can include a sentence like: “I would like to extend my support to the submission made by Digital Rights Watch”. You can also reference other organisations.
  * Really stuck? Get in touch with us, we’d love to help as best we can. 

#### **Looking for more? Here is a handful of our work in this space&#8230;**

  * [Online Safety Act explainer][1] 
  * [Submission on the Online Safety Bill][11]
  * [Submission on the draft Basic Online Safety Expectations][12]
  * [Submission on the Restricted Access Systems Declaration discussion paper][13] 
  * ‘[Flaws in new online safety laws][14]’, _The Saturday Paper_, by Lizzie O’Shea and Lucie Krahulcova 
  * ‘[Proposed online safety laws may do more harm than good][15]’, _The Canberra Times_, by Samantha Floreani
  * ‘[New law could ban some online adult content][16]’, _Triple J Hack,_ featuring Lucie Krahulcova
  * [Basic Online Safety Expectations][17], _3CR Community Radio,_ featuring Samantha Floreani (from 35 minutes on)

 [1]: https://digitalrightswatch.org.au/2021/02/11/explainer-the-online-safety-bill/
 [2]: https://www.eff.org/deeplinks/2020/10/facebooks-most-recent-transparency-report-demonstrates-pitfalls-automated-content
 [3]: https://www.vox.com/recode/2019/8/15/20806384/social-media-hate-speech-bias-black-african-american-facebook-twitter
 [4]: https://onlinecensorship.org/content/infographics
 [5]: https://www.theguardian.com/technology/2020/oct/20/instagram-censored-one-of-these-photos-but-not-the-other-we-must-ask-why
 [6]: https://saltyworld.net/algorithmicbiasreport-2/
 [7]: https://venturebeat.com/2018/04/25/zuckerberg-its-easier-to-detect-a-nipple-than-hate-speech-with-ai/
 [8]: https://digitalrightswatch.org.au/2021/04/30/explainer-anonymity-online-is-important/
 [9]: https://www.youtube.com/watch?v=XUVrmeRATJs&t=1s
 [10]: https://www.youtube.com/watch?v=sdBQAf5Xb5c&t=69s
 [11]: https://digitalrightswatch.org.au/2020/02/20/submission-to-consultation-on-a-new-online-safety-act/
 [12]: https://digitalrightswatch.org.au/2021/11/04/submission-draft-basic-online-safety-expectations/
 [13]: https://digitalrightswatch.org.au/2021/09/21/submission-restricted-access-system/
 [14]: https://www.thesaturdaypaper.com.au/opinion/topic/2021/03/13/flaws-new-online-safety-laws/161555400011272#hrd
 [15]: https://www.canberratimes.com.au/story/7124518/proposed-online-safety-measures-may-do-more-harm-than-good/
 [16]: https://www.abc.net.au/triplej/programs/hack/hack/13240936
 [17]: https://www.3cr.org.au/thursday-breakfast/episode-202110140700/raucous-anti-aukus-caucus-basic-online-safety-expectations