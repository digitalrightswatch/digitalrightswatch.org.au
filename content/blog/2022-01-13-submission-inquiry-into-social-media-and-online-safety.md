---
title: 'Submission: Inquiry into Social Media and Online Safety'
author: Samantha
authorThumb: /wp-content/uploads/2019/08/SamFloreani-150x150.png
date: 2022-01-13T01:05:44+00:00
url: /2022/01/13/submission-inquiry-into-social-media-and-online-safety/
featureImage: /wp-content/uploads/2022/01/jeremy-bezanger-9k_gCYLoH2g-unsplash-scaled-1.jpg
eg_vimeo_ratio:
  - 1
eg_youtube_ratio:
  - 1
eg_wistia_ratio:
  - 1
eg_html5_ratio:
  - 1
eg_soundcloud_ratio:
  - 1
eg_custom_meta_216:
  - 'true'
cybocfi_hide_featureImage:
  - yes
category:
  - Submissions
tags:
  - age verification
  - Online safety
  - social media

---
In December 2021, alongside the announcement of the Social Media (Anti-Trolling) Bill, the government announced a Parliamentary Inquiry into Social Media and Online Safety.

The Committee will conduct the Inquiry beginning in December 2021 and present its final report by 15 February 2022. Talk about a quick turnaround! This sadly continues the trend of rushed online safety consultations. You may also be wondering: shouldn&#8217;t this Inquiry have happened _before_ the Online Safety Act was passed? A very good question indeed.

Digital Rights Watch made a submission to the Committee, drawing upon our extensive participation in the online safety space in Australia over course of 2021. In it, we highlight five key messages we urge the Committee to consider over the course of the Inquiry:

  1. Address the causes, not just the symptoms.
  2. Online anonymity and pseudonymity are important, and warrant protection
  3. Age verification proposals create more harm than good
  4. Automated content moderationo is not a simple fix
  5. Robust digital security keeps us all safer in a connected world

We also urge the Committee to avoid conflating surveillance with safety**.**

The approach to online safety must always take into account the complexities of modern life, norms, and digital technologies. When the focus of online safety is solely on the symptoms— namely online abuse and harassment, misinformation, and defamation—without also considering the underlying business models, technological realities, legislative landscape, and social norms, the government risks _creating_ additional online harms, in its pursuit of mitigation. This is made worse by failing to listen to, or refusing to incorporate, feedback from the most affected communities.

#### [Read the full submission here. [PDF]][1]

 [1]: /wp-content/uploads/2022/01/Digital-Rights-Watch_Social-Media-and-Online-Safety-Inquiry-2022.pdf
