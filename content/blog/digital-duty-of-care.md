---
draft: false
title: Digital Duty of Care
date: 2025-07-28T04:16:34.700Z
authors: []
featureImage: https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Silicon_chip_from_a_computer_laser_mouse_under_a_microscope_50%D1%85.jpg/640px-Silicon_chip_from_a_computer_laser_mouse_under_a_microscope_50%D1%85.jpg
---
The Albanese government has [committed](https://minister.infrastructure.gov.au/rowland/media-release/new-duty-care-obligations-platforms-will-keep-australians-safer-online?) to legislating a "digital duty of care”, but what does that really mean and why do we want it?

Duty of care refers to the obligation that a business has to ensure that their actions, products, or services do not cause unreasonable harm to their customers. This concept has been well-established since 1932, thanks to [Donoghue v Stevenson](https://professionalnegligenceclaimsolicitors.co.uk/duty-of-care-key-tort-law-judgment-donoghue/): the famous snail-in-the-bottle-of-ginger-beer case. 

In terms of Internet companies, when their products cause unreasonable harm, we can use their legal duty of care to demand they stop. We have a variety of reasons for doing so.

From a feminist perspective, internet companies often fail to protect women from digital harms like [deepfakes](https://www.theparliamentmagazine.eu/news/article/how-sexually-explicit-deepfakes-undermine-democracy-and-womens-role-in-the-eu), [sextortion](https://www.afp.gov.au/news-centre/media-release/afp-warning-over-rise-sadistic-sextortion-online), and [cyberstalking](https://www.aihw.gov.au/family-domestic-and-sexual-violence/types-of-violence/stalking-surveillance). Meanwhile, the child-safety perspective raises [alarm](https://www.afp.gov.au/news-centre/media-release/concerns-over-children-accessing-extremist-material-online) about how easily children can access inappropriate content or fall victim to [online predators](https://abcnews.go.com/Nightline/experts-protect-children-online-predators/story?id=110192418). 

There is also a national security perspective to a digital duty of care. Far-right radicalisation is a [global](https://url1005.email.actionnetwork.org/ss/c/u001.SLdqY4re9NRChJwFnQ0ir77NP85M9wbIWvd6xKfBwnLIQalTLARQiaVrikLaJBycMT0s8B0Ufuw1F7Wup1edIT34GO3Mxn_B5Q8K4MATdUxxa0ps2ZeAwCxbU_Rkd2S7v23Ptm32bXR-IqPfstC25xxOlQsqGyDtjNc_gpDlGdY-AcY2JBcU0V_Vu91lXURZvfDDT7fsz14HhYEx4qhkqSn6ZNvsBPZikuJ4UkFOQupaPMPyzAW1eagPDgGDFXW2sfCx7qC6qzoOsKPaP7KAdroFfsXKmSvha-hlXSYKDiq2HoT3QBHrNGWnOW37TeRf1S4VASsYuZxLgnzveYCBYw/4ie/JmLGi7KdSMeRkwDjcS5uYA/h10/h001.cc37dBV_ytefvxGVY14OzLHNUjAReKwpLqsBfR4MylE) problem on many [online platforms](https://www.bbc.com/news/articles/cne4vw1x83po). Youtube’s algorithms in particular deserve scrutiny over their ability to lead individuals towards hateful content. A study by [Reset Tech Australia](https://url1005.email.actionnetwork.org/ss/c/u001.qUXRBnqZ7T8nxbpAcIVwoXFNoiOs_lcj8erSMRjRndY761VyuJG4zhOXEoiRPhu-In4F2yb2sUjcmAEzUV3NV8nHFBMZeBFJ_5Wl_1DvS_HDw5X2XDicQpqjskD3s2ssbD1EZ9FxTt46ciMo6mZPgSKUgvswtxwv28a2St7hhzc8rFqcx4Bea6xMKv7YPMaYHdn28lC_Cm2LO1o-RK9WJFUpr9ZWhFSClygcxYOeGNDLFvUhfhfJk6FZg5nLly7puvuqeXAuQOsfEIAHzlhkgLdvbdvS_uXsbRvPsobCWAPTre_c82vM0zBoNxVIOUt4XxZz_yfMi4-FhuR04e9t0w/4ie/JmLGi7KdSMeRkwDjcS5uYA/h11/h001.8VYUQ-Bfbvo9IErsCtunq2OCrm9-CD7jO2hlBGsH-OY) found that it took under 30 minutes for Youtube’s algorithm to pack a new user’s feed with misogynistic and racist content. 

A legislated digital duty of care has a strong argument behind it, but it carries practical risks too;

**Implementation is complicated.**

One major challenge is figuring out with whom the duty of care rests. For example, suppose a tech platform uses mandatory abuse material detection technology but it performs poorly and harms users as a result. Who’s responsible for that breach of a duty of care? The platform? The third-party provider of the detection software? The government for mandating it? And equally importantly, how would they be held accountable. 

**What constitutes reasonable steps to meet a duty of care?**

What denotes reasonable will depend on the nature of the organisation, the type of data it handles and its size. We should expect enormous internet platforms to take greater action to protect their users than small hobbyist sites. 

Too much flexibility surrounding what constitutes reasonable steps can result in large platforms being able to wriggle-out of their obligations, whereas too much rigidity can result in smaller sites being unduly punished. 

**It could open the door to overreach.**

Vitally, without strong privacy protections in place, Australians are vulnerable to censorship and surveillance under the banner of “care.” Companies could use the guise of fulfilling their duty of care to dig through user-data or behaviours. Germany’s Network Enforcement Act (Netzwerkdurchsetzungsgesetz, or NetzDG) is a cautionary tale here, it’s faced [harsh yet reasonable criticism](https://url1005.email.actionnetwork.org/ss/c/u001.NV3IV8RXB3BPG-RgoenRiq9PQOG79w2jNA1nJD6yz1aEBTq2Wp9rKXEFEJaz4cERoYTc8kiGYaLsqFD0EMJlXRLODF0DXQ4Ah-zY-7tL6Nsd7dzdbOeWsqCAUf4ul34v60p0JhDyAQFrH0njawcShccUPv_fksOMTp9ayrW8xM2ISFba7FDP7jfjjOeGHMQjDhcVhUIpR6hi9D-rv1CSQkF8E98TgCrA4WYwmap6gHuo0ZKWzu8HQIsVzxFmA2KqTjwOMbMBudE8Bnq4s0LlrNQWwwGe3JR62ypjPsx2oH94yep1oiVYhVjJHogS5-TxQw_UkMZcdrua6yL5lD9NzDe5WhXq1UXkymRHEI0AIFnvmT3BrMpS48zjsheoMFv3NQHyS3O4V7x9JZMtfe9GcggWx3Gsbk2WuWLb0bmoCSheX-i2I-gAAd7AtRFrDj1_ackaH-OYScsE6C3-2QctPXVK-W0pliRoWCJpzWdjkaE/4ie/JmLGi7KdSMeRkwDjcS5uYA/h12/h001._yh5P32HZkybAFIih7XocCUK3PXqV-oilcTMtnSRnVA) for enabling over-censorship and government surveillance in the name of protecting users.