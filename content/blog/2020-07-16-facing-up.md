---
title: 'Event: Facing up to facial recognition'
authors: [sam]
date: 2020-07-16T10:13:20+00:00
url: /2020/07/16/facing-up/
featureImage: /wp-content/uploads/2020/07/facialrec-03.png
eg_vimeo_ratio:
  - 1
eg_youtube_ratio:
  - 1
eg_wistia_ratio:
  - 1
eg_html5_ratio:
  - 1
eg_soundcloud_ratio:
  - 1
eg_custom_meta_216:
  - 'true'
category:
  - Events
tags:
  - event
  - Facial recognition
  - surveillance

---
Facial recognition technology has been deployed across Australia and around the world. It's in the streets, at major sporting events and at the 7/11. Most alarmingly, it's increasingly being used by law enforcement and government at all levels &#8211; all without any of us getting a say.

Facial recognition that enables mass surveillance is a threat to human rights and civil liberties.

On Thursday 30 July Digital Rights Watch held an online conversation to dig a little deeper. Hosted by Digital Rights Watch Board Member and digital security consultant, Lilly Ryan, we held a wide-ranging discussion with ABC technology reporter Ariel Bogle, law and technology scholar Jake Goldenfein and technologist and activist Kathryn Gledhill-Tucker.

While we know that facial recognition technology is riddled with flaws, false positives and biases, this discussion explored the question of if improving the technology is enough to prevent harm, and if it&#8217;s even compatible with a liberal society.

Much of the facial recognition public commentary has been dominated by the US narrative, so this conversation was grounded in the Australian context. How does AI-driven surveillance for policing fit within the aim to &#8216;Close the Gap&#8217; for Aboriginal and Torres Strait Islander people? What is the role of the media in establishing a public technological literacy in Australia? What are some of the challenges we face when it comes to transparency of the facial recognition tools that the federal and state police are using? And within the context of Australian legislation and infrastructure, what might privacy-protecting legislation look like?

In the midst of the Black Lives Matter movement, now more than ever the use of national-security style surveillance techniques by police and government are being called into question. Often justified as cost-effective ways to avoid human bias and error, in reality the use of technologies such as facial recognition has been shown to actually worsen bias, overreach and abuse in policing &#8211; especially against Black, Indigenous and People of Colour.

As we begin to reimagine the possibilities of how we might make positive changes in our society, it's never been more important to come together to face up to the dangers of facial recognition.

You can watch the recording of the full session below.

{{< youtube >}}

